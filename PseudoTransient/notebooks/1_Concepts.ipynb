{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Instantiating arrays\n",
    "Julia offers native support for multi-dimensional arrays and \"array programming\" similar to MATLAB.\n",
    "There are different ways to instantiate arrays; for example, you can initialize an empty $4 \\times 4$ array that will\n",
    "contain only double precision floats (`Float64`) as"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4×4 Matrix{Float64}:\n 2.14315e-314  2.14315e-314  0.0  0.0\n 5.3e-322      8.84e-322     0.0  0.0\n 2.14315e-314  0.0           0.0  0.0\n 8.35e-322     0.0           0.0  0.0"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "cell_type": "code",
   "source": [
    "A = Array{Float64, 2}(undef, 4, 4)"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this particular case, `Matrix{T}` is an alias type of `Array{Float64, 2}`, so you can also initialize it as"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4×4 Matrix{Float64}:\n 0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "A = Matrix{Float64}(undef, 4, 4)"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Other common `Array` constructors are `zeros`, `ones`, `fill`, and `rand`"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4×4 Matrix{Float64}:\n 0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "A = zeros(4, 4)"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4×4 Matrix{Float64}:\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "A = ones(4, 4)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4-element Vector{Int64}:\n 4\n 4\n 4\n 4"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "A = fill(4, 4)"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4×4 Matrix{Float64}:\n 0.95417   0.456829  0.718908  0.428308\n 0.989655  0.17084   0.864178  0.625751\n 0.580083  0.492063  0.311881  0.509103\n 0.831883  0.563287  0.68434   0.727435"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "A = rand(4, 4)"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Array indexing and mutation\n",
    "To read individual elements of an array, we use square brackets"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7674683187149418"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "A = rand(4)\n",
    "A[1]"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9126838869572659"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "B = rand(4, 4)\n",
    "B[1, 1]"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.21634533832756941"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "C = rand(4, 4, 4)\n",
    "C[1, 1, 1]"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also read chunks of the array at once (_NOTE_ this will allocate a new array)"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2×2 Matrix{Float64}:\n 0.912684  0.838086\n 0.649304  0.22111"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "B[1:2, 1:2]"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "To make a view of an array and avoid allocating new intermediate arrays, we can use the macro `@views`"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2×2 view(::Matrix{Float64}, 1:2, 1:2) with eltype Float64:\n 0.912684  0.838086\n 0.649304  0.22111"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "@views B[1:2, 1:2]"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "As in MATLAB, we can also slice `Array`s"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4-element view(::Matrix{Float64}, :, 1) with eltype Float64:\n 0.9126838869572659\n 0.6493040512304186\n 0.8429213886710439\n 0.7184174531757884"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "cell_type": "code",
   "source": [
    "@views B[:, 1] # take the first column"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4-element view(::Matrix{Float64}, 1, :) with eltype Float64:\n 0.9126838869572659\n 0.838086007674934\n 0.7081457691848612\n 0.32596268463484646"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "cell_type": "code",
   "source": [
    "@views B[1, :] # take the first row"
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Broadcasting\n",
    "`Array`s support element-wise (broadcasting) linear algebra operators, we only need to add a dot `.` before the operator. For example"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4×4 Matrix{Float64}:\n 0.905178  1.01826  0.108175  0.406362\n 0.998729  1.59776  0.260611  1.69662\n 1.29002   1.4254   1.03904   1.40882\n 0.625926  1.24421  0.142354  0.405477"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "cell_type": "code",
   "source": [
    "A = rand(4, 4)\n",
    "B = rand(4, 4)\n",
    "C = A .+ B"
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4×4 Matrix{Float64}:\n 0.991087  0.181298  3.91544    0.845069\n 4.00612   0.971274  0.456839   1.06402\n 1.34225   2.27386   1.11596    0.468768\n 5.66158   1.44461   0.0686793  0.0680844"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "cell_type": "code",
   "source": [
    "D = A ./ B"
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we need to broadcast several operators in a single line, we can fuse them with the `@.` macro"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4×4 Matrix{Float64}:\n 0.187077    0.756574  5.23903e-5  0.0197113\n 0.0397503   1.04964   0.00833983  1.14638\n 0.391316    0.270206  0.250539    1.29616\n 0.00552605  0.322302  0.00252587  0.0584371"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "cell_type": "code",
   "source": [
    "E = @. (A + B) * B^2"
   ],
   "metadata": {},
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "Broadcasting does not apply only to operators, but to any function that acts on scalars. For example, we can broadcast `sin` to any `Array`"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4×4 Matrix{Float64}:\n 0.435472  0.15564   0.0860609   0.185047\n 0.716817  0.708408  0.0816322   0.767301\n 0.673742  0.836034  0.520972    0.434637\n 0.507228  0.670772  0.00914832  0.025844"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "cell_type": "code",
   "source": [
    "sin.(A)"
   ],
   "metadata": {},
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions\n",
    "Functions can be instantiated in several ways, with the \"standard\" way being"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "foo (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "cell_type": "code",
   "source": [
    "function foo(x)\n",
    "    y = x + rand()\n",
    "    return y\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "A function (or code block, i.e. `if/elseif` statements or `let` blocks) will return their **last line**. Therefore, we can also write the previous function as"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "foo (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "cell_type": "code",
   "source": [
    "function foo(x)\n",
    "    y = x + rand()\n",
    "    y\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 19
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "foo (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "cell_type": "code",
   "source": [
    "function foo(x)\n",
    "    y = x + rand()\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "or more concisely as a one-liner"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "foo (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "cell_type": "code",
   "source": [
    "foo(x) = x + rand()"
   ],
   "metadata": {},
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "Functions can also return multiple arguments"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "foo (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "cell_type": "code",
   "source": [
    "function foo(x)\n",
    "    y = x + rand()\n",
    "    return x, y\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "Anonymous functions also exist in Julia"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5.701358170214397"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "cell_type": "code",
   "source": [
    "fun = x -> x + rand()\n",
    "fun(5)"
   ],
   "metadata": {},
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "All the information regarding functions can be found [here](https://docs.julialang.org/en/v1/manual/functions/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## In-place vs out-of-place functions\n",
    "It is common that you need to store the results of matrix operations in a new array. Creating the new destination array will obviously allocate, if you need to do this operation just once, an out-of-place kernel will do just fine"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "outofplace (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "cell_type": "code",
   "source": [
    "function outofplace(A, B)\n",
    "    C = similar(A)\n",
    "    for i in axes(A, 1), j in axes(A, 2)\n",
    "        C[i, j] = B[i, j] * C[i, j]\n",
    "    end\n",
    "    return C\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "however, it is frequent you need to run the kernel several times, in which case you want to avoid allocating the destination array every time. In this case, you can use an in-place kernel, by pre-allocating the destination array and just mutating it:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "inplace! (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "cell_type": "code",
   "source": [
    "function inplace!(C, A, B)\n",
    "    for i in axes(A, 1), j in axes(A, 2)\n",
    "        C[i, j] = B[i, j] * C[i, j]\n",
    "    end\n",
    "    return nothing\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "note that in the latter case we do not return anything, as Julia passes arguments by reference to the functions.\n",
    "Also note the `!` at the end for the in-place function, this is a convention in Julia to denote that the function mutates its arguments (where the mutating arguments are the first ones)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Benchmarking\n",
    "In Julia, it is extremely easy (and extremely useful to catch performance issues or regressions) to benchmark the performance of any function.\n",
    "Julia has the built-in `@time` and `@elapsed` macros that measure the performance of a single function call. However, these are not\n",
    "very accurate and it's best to use external packages, namely [BenchmarkTools.jl](https://juliaci.github.io/BenchmarkTools.jl/stable/) or [Chairmarks](https://github.com/LilithHafner/Chairmarks.jl)\n",
    "We can benchmark our `outofplace` and `inplace!` functions with `BenchmarkTools.jl`"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "BenchmarkTools.Trial: 10000 samples with 163 evaluations.\n Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m646.221 ns\u001b[22m\u001b[39m … \u001b[35m238.168 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m 0.00% … 99.52%\n Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m  1.149 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m 0.00%\n Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m  1.560 μs\u001b[22m\u001b[39m ± \u001b[32m  3.346 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m26.41% ± 15.99%\n\n  \u001b[39m▅\u001b[39m▆\u001b[34m█\u001b[39m\u001b[39m▆\u001b[32m▃\u001b[39m\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n  \u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m▇\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▁\u001b[39m▄\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▄\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▇\u001b[39m▅\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m \u001b[39m█\n  646 ns\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m       13.3 μs \u001b[0m\u001b[1m<\u001b[22m\n\n Memory estimate\u001b[90m: \u001b[39m\u001b[33m8.08 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m3\u001b[39m."
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "cell_type": "code",
   "source": [
    "using BenchmarkTools\n",
    "A, B, C = rand(32, 32), rand(32, 32), zeros(32, 32)\n",
    "@benchmark outofplace($A, $B)"
   ],
   "metadata": {},
   "execution_count": 26
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "BenchmarkTools.Trial: 10000 samples with 190 evaluations.\n Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m530.700 ns\u001b[22m\u001b[39m … \u001b[35m 4.957 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m549.563 ns              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m565.547 ns\u001b[22m\u001b[39m ± \u001b[32m92.890 ns\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n\n  \u001b[39m█\u001b[39m \u001b[39m▁\u001b[34m▄\u001b[39m\u001b[39m▅\u001b[39m▂\u001b[32m▆\u001b[39m\u001b[39m▄\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\n  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▄\u001b[39m▃\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▃\u001b[39m▄\u001b[39m▅\u001b[39m▃\u001b[39m▃\u001b[39m▅\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▄\u001b[39m▂\u001b[39m▃\u001b[39m▄\u001b[39m▄\u001b[39m \u001b[39m█\n  531 ns\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m       892 ns \u001b[0m\u001b[1m<\u001b[22m\n\n Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "cell_type": "code",
   "source": [
    "@benchmark inplace!($C, $A, $B)"
   ],
   "metadata": {},
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "or with `Chairmarks.jl`"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Benchmark: 1851 samples with 25 evaluations\nmin    660.000 ns (3 allocs: 8.078 KiB)\nmedian 1.450 μs (3 allocs: 8.078 KiB)\nmean   1.932 μs (3 allocs: 8.078 KiB, 0.05% gc time)\nmax    772.100 μs (3 allocs: 8.078 KiB, 99.73% gc time)"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "cell_type": "code",
   "source": [
    "using Chairmarks\n",
    "@be outofplace($A, $B)"
   ],
   "metadata": {},
   "execution_count": 28
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Benchmark: 3079 samples with 55 evaluations\nmin    529.545 ns\nmedian 532.582 ns\nmean   545.744 ns\nmax    2.394 μs"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "cell_type": "code",
   "source": [
    "@be inplace!($C, $A, $B)"
   ],
   "metadata": {},
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Code parallelization\n",
    "Julia supports parallel computing on both CPUs and GPUs throught different packages\n",
    "- CPU:\n",
    "  1. [Threads.jl](https://docs.julialang.org/en/v1/manual/multi-threading/) for multithreading (i.e. shared memory)\n",
    "  2. [Distributed.jl](https://docs.julialang.org/en/v1/stdlib/Distributed/) for distributed parallelization (i.e. across multiple CPUs)\n",
    "  3. [MPI.jl](https://github.com/JuliaParallel/MPI.jl) for distributed parallelization (i.e. across multiple CPUs)\n",
    "- GPU:\n",
    "  1. [CUDA.jl](https://github.com/JuliaGPU/CUDA.jl) for Nvidia GPU cards\n",
    "  2. [AMDGPU.jl](https://github.com/JuliaGPU/AMDGPU.jl) for AMD GPU cards\n",
    "  3. [Metal.jl](https://github.com/JuliaGPU/Metal.jl) for Apple M-series chips"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multithreading\n",
    "Julia does not parallelize code automatically, but it provides tools to do so. This means that \"array-style programming\" ala MATLAB or Numpy will not automatically parallelize in Julia.\n",
    "However, is is very simple to paralleliza loops (and **loops are fast**) in Julia.\n",
    "For example, let's parallelize the AXPY (\"A·X Plus Y\") BLAS kernel"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$A = \\alpha B + C$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "where $B$ and $C$ are random $n\\times n$ matrices."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "([0.9017577335196968 0.26362597419050116 … 0.815485015563698 0.5390991405661553; 0.7552910855718593 0.20251391761106563 … 0.16989708483661548 0.2862445581497084; … ; 0.7164209975478115 0.8030591530654273 … 0.3253417860612724 0.13110843391669236; 0.10510440338622262 0.16728178127283078 … 0.8832041533430278 0.9654639603035552], [0.5623499335550435 0.6807843549477879 … 0.9431753772464664 0.9822629803628565; 0.989402682608007 0.30493412139134213 … 0.33470820547071434 0.050917087524446236; … ; 0.3118613399272522 0.6863504100768406 … 0.7478398918188336 0.24349331212780168; 0.30216638248886607 0.4869803198603445 … 0.20406090108241748 0.31505428764359833])"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "cell_type": "code",
   "source": [
    "n    = 128\n",
    "α    = rand()\n",
    "Z    = zeros(n, n)\n",
    "X, Y = rand(n, n), rand(n, n)"
   ],
   "metadata": {},
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "To parallelize this operation, we simply need to write the kernel as a loop and the put the `Threads.@threads` macro before the loop"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "axpy! (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "cell_type": "code",
   "source": [
    "function axpy!(Z, X, Y, α)\n",
    "    @assert size(Z) == size(X) == size(Y)\n",
    "    Threads.@threads for i in eachindex(X)\n",
    "        Z[i] = α * X[i] + Y[i]\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPU programming\n",
    "Unlike with CPU code, broadcasting works and one can run GPU-accelerated  \"array-style programming\" code, as long as the arrays are properly allocated on the GPU device. For example, the AXPY operation can be run on the GPU of a M-series chip as follows:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "128×128 Metal.MtlMatrix{Float32, Metal.PrivateStorage}:\n 0.815596   0.46488   0.172365  0.567152   …  0.394312  0.954644  0.0638175\n 0.0647891  0.425158  0.778653  0.339724      1.15946   0.734933  0.789722\n 0.610507   0.817783  0.786538  0.828534      0.678247  0.960341  0.417979\n 0.733641   0.500035  0.540654  0.309561      1.10047   0.610939  0.554279\n 0.975635   0.950932  0.90331   1.06185       0.97306   0.915283  0.912188\n 0.60448    0.943942  0.295774  0.489803   …  0.337867  0.942225  0.867952\n 0.555816   0.537579  0.733592  0.904657      0.244592  0.812801  0.88357\n 0.43215    0.730572  0.788118  0.538585      0.593145  0.898982  0.455808\n 0.373605   0.966982  0.979465  0.741311      0.714037  0.798405  0.753471\n 0.294809   0.636492  1.23228   0.387727      0.340071  1.02004   0.21748\n ⋮                                         ⋱  ⋮                   \n 0.783568   0.285133  0.709449  0.179245      0.128245  0.24625   0.314937\n 0.298081   0.598472  0.505408  0.903033   …  0.808644  0.236959  0.567551\n 0.193394   0.896074  0.906044  0.800965      0.883953  0.807718  0.40032\n 1.07576    0.388339  0.336898  0.535247      1.03221   0.775464  0.866696\n 0.838043   1.06104   0.342168  0.302818      0.260044  0.618524  0.812381\n 0.248005   0.695758  0.87124   0.984746      0.700051  0.755459  0.144945\n 0.517236   0.692816  0.970464  0.0761816  …  0.865967  0.922039  1.03076\n 0.473643   0.580466  0.527167  0.43673       0.579477  0.973318  1.24298\n 0.83316    0.445987  0.998209  0.375934      1.08583   0.631503  0.688821"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "cell_type": "code",
   "source": [
    "using Metal\n",
    "n    = 128\n",
    "α    = rand(Float32)\n",
    "Z    = Metal.zeros(n, n)\n",
    "X, Y = Metal.rand(n, n), Metal.rand(n, n)\n",
    "Z    = @. α * X + Y"
   ],
   "metadata": {},
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you have a NVIDIA or AMD GPU card, you can respectively use the CUDA.jl or AMDGPU.jl packages to run the same code just using the `CUDA.zeros`, `CUDA.rand` or `AMDGPU.zeros`, `AMDGPU.rand` allocators instead.\n",
    "However, it is often more convinient to write function kernels, as not everything can be efficiently written an array programming style."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"../figs/cuda_grid.png\" alt=\"drawing\" width=\"300\"/>\n",
    "</p>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using first linear indexing, the previous example would be written as follows"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Metal.HostKernel{typeof(Main.var\"##286\".axpy!), Tuple{Metal.MtlDeviceMatrix{Float32, 1}, Metal.MtlDeviceMatrix{Float32, 1}, Metal.MtlDeviceMatrix{Float32, 1}, Float32}}(Main.var\"##286\".axpy!, Metal.MTL.MTLComputePipelineStateInstance (object of type AGXG14XFamilyComputePipeline))"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "cell_type": "code",
   "source": [
    "function axpy!(Z, X, Y, α)\n",
    "    i = thread_position_in_grid_1d()\n",
    "    if i ≤ length(Z)\n",
    "        Z[i] = α * X[i] + Y[i]\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "nthreads = 512\n",
    "ngroups  = cld(n^2, nthreads)\n",
    "@metal threads = nthreads groups=ngroups axpy!(Z, X, Y, α)"
   ],
   "metadata": {},
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or like this if we prefer to use Cartesian indexing:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Metal.HostKernel{typeof(Main.var\"##286\".axpy_Metal!), Tuple{Metal.MtlDeviceMatrix{Float32, 1}, Metal.MtlDeviceMatrix{Float32, 1}, Metal.MtlDeviceMatrix{Float32, 1}, Float32}}(Main.var\"##286\".axpy_Metal!, Metal.MTL.MTLComputePipelineStateInstance (object of type AGXG14XFamilyComputePipeline))"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "cell_type": "code",
   "source": [
    "function axpy_Metal!(Z, X, Y, α)\n",
    "    (i,j) = thread_position_in_grid_2d()\n",
    "    if i ≤ size(Z, 1) && j ≤ size(Z, 2)\n",
    "        Z[i, j] = α * X[i, j] + Y[i, j]\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "nthreads = 16, 16\n",
    "ngroups  = cld.(n, nthreads)\n",
    "Metal.@sync @metal threads = nthreads groups=ngroups axpy_Metal!(Z, X, Y, α)"
   ],
   "metadata": {},
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "> [!WARNING]\n",
    "> Multithreaded and GPU code **is not thread safe**. It is up to the user to avoid race conditions. An example of non thread-safe code is a reduction:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "let\n",
    "    A = rand(20)\n",
    "    sum = 0.0\n",
    "    Threads.@threads for Ai in A\n",
    "        sum += Ai # <- race condition\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Backend abstraction\n",
    "As you can see, if we want to write a code that is highly portable and run it multiple backends, we need to write a specific kernel for each hardware.\n",
    "This is tedious and leads to a lot of code redudancy and prone to copy-pasting bugs. One of the advantages of Julia, is that we can easily write code that is agnostic to the backend.\n",
    "This is done using one of these packages:\n",
    "  - [ParallelStencil.jl](https://github.com/omlins/ParallelStencil.jl); supports CUDA.jl, AMDGPU.jl, and Metal.jl.\n",
    "  - [KernelAbstractions.jl](https://github.com/JuliaGPU/KernelAbstractions.jl); supports CUDA.jl and AMDGPU.jl."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ParallelStencil.jl\n",
    "Kernel parallelization is essentially done using two new macros: `@parallel` and `@parallel_indices`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using ParallelStencil\n",
    "@init_parallel_stencil(Threads, Float64, 2) # @init_parallel_stencil(Backend, TypePrecission, Dimension)\n",
    "\n",
    "n    = 128\n",
    "α    = rand()\n",
    "Z    = @zeros(n, n)\n",
    "X, Y = @rand(n, n), @rand(n, n)\n",
    "\n",
    "@parallel_indices (i,j) function axpy_PS!(Z, X, Y, α)\n",
    "    Z[i, j] = α * X[i, j] + Y[i, j]\n",
    "    return\n",
    "end\n",
    "\n",
    "@parallel (1:n, 1:n) axpy_PS!(Z, X, Y, α)"
   ],
   "metadata": {},
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KernelAbstractions.jl\n",
    "This package requires a bit more written, as now we need to define a kernel and a launcher function to parallelize our code"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "128×128 Metal.MtlMatrix{Float32, Metal.PrivateStorage}:\n 0.590338   0.148476   0.309626  …  0.734281   0.17075      0.46747\n 0.816651   0.738104   0.408657     0.70122    0.980236     0.473899\n 0.306998   0.817772   0.474625     0.44708    0.769124     0.08973\n 0.610878   0.759066   0.581855     0.0176271  0.0149094    0.329428\n 0.323795   0.222844   0.69302      0.651956   0.912801     0.52422\n 0.535055   0.62285    0.170234  …  0.320966   0.710759     0.91978\n 0.887648   0.795175   0.589949     0.235552   0.155195     0.219062\n 0.698051   0.321051   0.286161     0.839727   0.650872     0.857994\n 0.538854   0.0149783  0.219537     0.793466   0.155159     0.160329\n 0.164456   0.643001   0.985792     0.956448   0.376456     0.290343\n ⋮                               ⋱  ⋮                       \n 0.836447   0.467763   0.674723     0.988468   0.967462     0.671614\n 0.0134086  0.0804033  0.560772  …  0.919006   0.92813      0.133023\n 0.0738519  0.693142   0.153843     0.242448   0.0284514    0.398686\n 0.4869     0.196245   0.260845     0.644351   0.763348     0.310469\n 0.507428   0.244819   0.190769     0.521613   0.000397106  0.043594\n 0.690339   0.444615   0.329932     0.364031   0.476236     0.7237\n 0.853117   0.869061   0.184618  …  0.27529    0.406297     0.505061\n 0.691289   0.87555    0.392173     0.995734   0.0170084    0.364689\n 0.690348   0.390871   0.417653     0.831985   0.396494     0.892555"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "cell_type": "code",
   "source": [
    "using Metal # comment out to run on the CPU; or load CUDA / AMDGPU instead\n",
    "using KernelAbstractions, Random\n",
    "\n",
    "backend = MetalBackend() # other valid backends: CPU(), CUDABackend(), AMDGPUBackend()\n",
    "type    = Float32\n",
    "n       = 128\n",
    "α       = rand(type)\n",
    "Z       = KernelAbstractions.zeros(backend, type, n, n)\n",
    "X       = rand!(allocate(backend, type, n, n))\n",
    "Y       = rand!(allocate(backend, type, n, n))"
   ],
   "metadata": {},
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "source": [
    "kernel"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "axpy_KA_kernel! (generic function with 4 methods)"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "cell_type": "code",
   "source": [
    "@kernel function axpy_KA_kernel!(Z, X, Y, α)\n",
    "    i, j = @index(Global, NTuple)\n",
    "    Z[i, j] = α * X[i, j] + Y[i, j]\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": [
    "launcher"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "axpy_KA! (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "cell_type": "code",
   "source": [
    "function axpy_KA!(Z, X, Y, α)\n",
    "    backend = get_backend(Z)\n",
    "    @assert size(X) == size(Y) == size(Z)\n",
    "    @assert get_backend(X) == get_backend(Y) == backend\n",
    "\n",
    "    nthreads = 32, 32\n",
    "    kernel = axpy_KA_kernel!(backend, nthreads)\n",
    "    kernel(Z, X, Y, α, ndrange = size(Z))\n",
    "    KernelAbstractions.synchronize(backend)\n",
    "    return\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.0-rc3"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.0-rc3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
